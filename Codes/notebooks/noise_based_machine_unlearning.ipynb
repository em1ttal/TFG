{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Noise-Based Machine Unlearning Methods for Tabular Data\n",
        "\n",
        "This notebook implements various machine unlearning techniques that add noise to model parameters.\n",
        "\n",
        "## Methods Implemented:\n",
        "1. **Gaussian Noise Injection** - Add Gaussian noise to weights\n",
        "2. **Laplacian Noise Injection** - Add Laplacian noise for differential privacy\n",
        "3. **Adaptive Noise Scaling** - Scale noise based on parameter importance\n",
        "4. **Layer-wise Noise Injection** - Different noise levels per layer\n",
        "5. **Gradient-based Noise** - Noise proportional to gradient magnitudes\n",
        "\n",
        "## Evaluation Metrics:\n",
        "- Forget set accuracy (should decrease)\n",
        "- Retain set accuracy (should maintain)\n",
        "- Test set accuracy (overall performance)\n",
        "- Parameter distance from original model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n",
            "PyTorch version: 2.7.1\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader, Subset\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from copy import deepcopy\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(42)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Generate Tabular Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset shape: (2000, 20)\n",
            "Number of features: 20\n",
            "Class distribution: [ 986 1014]\n",
            "\n",
            "Data splits:\n",
            "Retain set: 1440 samples\n",
            "Forget set: 160 samples\n",
            "Test set: 400 samples\n",
            "\n",
            "Data preparation complete!\n"
          ]
        }
      ],
      "source": [
        "# Generate synthetic tabular dataset for binary classification\n",
        "n_samples = 2000\n",
        "n_features = 20\n",
        "n_informative = 15\n",
        "n_redundant = 3\n",
        "\n",
        "X, y = make_classification(\n",
        "    n_samples=n_samples,\n",
        "    n_features=n_features,\n",
        "    n_informative=n_informative,\n",
        "    n_redundant=n_redundant,\n",
        "    n_classes=2,\n",
        "    random_state=42,\n",
        "    flip_y=0.1  # Add some noise\n",
        ")\n",
        "\n",
        "print(f\"Dataset shape: {X.shape}\")\n",
        "print(f\"Number of features: {n_features}\")\n",
        "print(f\"Class distribution: {np.bincount(y)}\")\n",
        "\n",
        "# Split into train, forget, retain, and test sets\n",
        "# Train set will be split into forget and retain sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Further split training set into forget (10%) and retain (90%) sets\n",
        "forget_ratio = 0.1\n",
        "X_retain, X_forget, y_retain, y_forget = train_test_split(\n",
        "    X_train, y_train, test_size=forget_ratio, random_state=42, stratify=y_train\n",
        ")\n",
        "\n",
        "print(f\"\\nData splits:\")\n",
        "print(f\"Retain set: {X_retain.shape[0]} samples\")\n",
        "print(f\"Forget set: {X_forget.shape[0]} samples\")\n",
        "print(f\"Test set: {X_test.shape[0]} samples\")\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_retain_scaled = scaler.fit_transform(X_retain)\n",
        "X_forget_scaled = scaler.transform(X_forget)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_retain_tensor = torch.FloatTensor(X_retain_scaled).to(device)\n",
        "y_retain_tensor = torch.LongTensor(y_retain).to(device)\n",
        "X_forget_tensor = torch.FloatTensor(X_forget_scaled).to(device)\n",
        "y_forget_tensor = torch.LongTensor(y_forget).to(device)\n",
        "X_test_tensor = torch.FloatTensor(X_test_scaled).to(device)\n",
        "y_test_tensor = torch.LongTensor(y_test).to(device)\n",
        "\n",
        "print(\"\\nData preparation complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Define Neural Network Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TabularClassifier(nn.Module):\n",
        "    \"\"\"Neural network for tabular binary classification\"\"\"\n",
        "    \n",
        "    def __init__(self, input_size, hidden_sizes=[64, 32, 16], num_classes=2, dropout=0.3):\n",
        "        super(TabularClassifier, self).__init__()\n",
        "        \n",
        "        layers = []\n",
        "        prev_size = input_size\n",
        "        \n",
        "        # Build hidden layers\n",
        "        for hidden_size in hidden_sizes:\n",
        "            layers.append(nn.Linear(prev_size, hidden_size))\n",
        "            layers.append(nn.BatchNorm1d(hidden_size))\n",
        "            layers.append(nn.ReLU())\n",
        "            layers.append(nn.Dropout(dropout))\n",
        "            prev_size = hidden_size\n",
        "        \n",
        "        # Output layer\n",
        "        layers.append(nn.Linear(prev_size, num_classes))\n",
        "        \n",
        "        self.network = nn.Sequential(*layers)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "    \n",
        "    def get_layer_names(self):\n",
        "        \"\"\"Get names of linear layers for targeted noise injection\"\"\"\n",
        "        return [name for name, module in self.named_modules() if isinstance(module, nn.Linear)]\n",
        "\n",
        "# Initialize model\n",
        "model = TabularClassifier(\n",
        "    input_size=n_features,\n",
        "    hidden_sizes=[64, 32, 16],\n",
        "    num_classes=2,\n",
        "    dropout=0.3\n",
        ").to(device)\n",
        "\n",
        "print(\"Model Architecture:\")\n",
        "print(model)\n",
        "print(f\"\\nTotal parameters: {sum(p.numel() for p in model.parameters())}\")\n",
        "print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Training and Evaluation Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model(model, X_train, y_train, epochs=50, batch_size=32, lr=0.001, verbose=True):\n",
        "    \"\"\"Train the model on given data\"\"\"\n",
        "    model.train()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    \n",
        "    # Create DataLoader\n",
        "    train_dataset = TensorDataset(X_train, y_train)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    \n",
        "    losses = []\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss = 0.0\n",
        "        \n",
        "        for batch_X, batch_y in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(batch_X)\n",
        "            loss = criterion(outputs, batch_y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "        avg_loss = epoch_loss / len(train_loader)\n",
        "        losses.append(avg_loss)\n",
        "        \n",
        "        if verbose and (epoch + 1) % 10 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}')\n",
        "    \n",
        "    return losses\n",
        "\n",
        "def evaluate_model(model, X, y):\n",
        "    \"\"\"Evaluate model accuracy\"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(X)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        accuracy = 100 * (predicted == y).sum().item() / y.size(0)\n",
        "    return accuracy\n",
        "\n",
        "def get_model_state_dict_copy(model):\n",
        "    \"\"\"Get a deep copy of model's state dict\"\"\"\n",
        "    return {name: param.clone().detach() for name, param in model.state_dict().items()}\n",
        "\n",
        "def calculate_parameter_distance(state_dict1, state_dict2):\n",
        "    \"\"\"Calculate L2 distance between two model state dicts\"\"\"\n",
        "    distance = 0.0\n",
        "    for key in state_dict1.keys():\n",
        "        if 'weight' in key or 'bias' in key:\n",
        "            distance += torch.norm(state_dict1[key] - state_dict2[key]).item() ** 2\n",
        "    return np.sqrt(distance)\n",
        "\n",
        "print(\"Training and evaluation functions defined!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Train Original Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train on full training set (retain + forget)\n",
        "X_full_train = torch.cat([X_retain_tensor, X_forget_tensor], dim=0)\n",
        "y_full_train = torch.cat([y_retain_tensor, y_forget_tensor], dim=0)\n",
        "\n",
        "print(\"Training original model on full training set...\")\n",
        "train_losses = train_model(model, X_full_train, y_full_train, epochs=100, lr=0.001)\n",
        "\n",
        "# Evaluate original model\n",
        "retain_acc = evaluate_model(model, X_retain_tensor, y_retain_tensor)\n",
        "forget_acc = evaluate_model(model, X_forget_tensor, y_forget_tensor)\n",
        "test_acc = evaluate_model(model, X_test_tensor, y_test_tensor)\n",
        "\n",
        "print(\"\\n=== Original Model Performance ===\")\n",
        "print(f\"Retain Set Accuracy: {retain_acc:.2f}%\")\n",
        "print(f\"Forget Set Accuracy: {forget_acc:.2f}%\")\n",
        "print(f\"Test Set Accuracy: {test_acc:.2f}%\")\n",
        "\n",
        "# Save original model state\n",
        "original_model_state = get_model_state_dict_copy(model)\n",
        "\n",
        "# Plot training loss\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(train_losses)\n",
        "plt.title('Original Model Training Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Machine Unlearning Methods\n",
        "\n",
        "### Method 1: Gaussian Noise Injection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def gaussian_noise_unlearning(model, sigma=0.01):\n",
        "    \"\"\"\n",
        "    Add Gaussian noise to all model parameters.\n",
        "    \n",
        "    Args:\n",
        "        model: PyTorch model\n",
        "        sigma: Standard deviation of Gaussian noise\n",
        "    \"\"\"\n",
        "    unlearned_model = deepcopy(model)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for name, param in unlearned_model.named_parameters():\n",
        "            if 'weight' in name or 'bias' in name:\n",
        "                # Add Gaussian noise\n",
        "                noise = torch.randn_like(param) * sigma\n",
        "                param.add_(noise)\n",
        "    \n",
        "    return unlearned_model\n",
        "\n",
        "# Test different noise levels\n",
        "sigma_values = [0.001, 0.005, 0.01, 0.05, 0.1]\n",
        "gaussian_results = []\n",
        "\n",
        "print(\"Testing Gaussian Noise Unlearning...\\n\")\n",
        "\n",
        "for sigma in sigma_values:\n",
        "    # Apply unlearning\n",
        "    unlearned_model = gaussian_noise_unlearning(model, sigma=sigma)\n",
        "    \n",
        "    # Evaluate\n",
        "    retain_acc = evaluate_model(unlearned_model, X_retain_tensor, y_retain_tensor)\n",
        "    forget_acc = evaluate_model(unlearned_model, X_forget_tensor, y_forget_tensor)\n",
        "    test_acc = evaluate_model(unlearned_model, X_test_tensor, y_test_tensor)\n",
        "    \n",
        "    # Calculate parameter distance\n",
        "    param_dist = calculate_parameter_distance(\n",
        "        original_model_state,\n",
        "        get_model_state_dict_copy(unlearned_model)\n",
        "    )\n",
        "    \n",
        "    gaussian_results.append({\n",
        "        'sigma': sigma,\n",
        "        'retain_acc': retain_acc,\n",
        "        'forget_acc': forget_acc,\n",
        "        'test_acc': test_acc,\n",
        "        'param_dist': param_dist\n",
        "    })\n",
        "    \n",
        "    print(f\"Sigma={sigma:.3f}: Retain={retain_acc:.2f}%, Forget={forget_acc:.2f}%, Test={test_acc:.2f}%, Dist={param_dist:.4f}\")\n",
        "\n",
        "# Convert to DataFrame for easier analysis\n",
        "gaussian_df = pd.DataFrame(gaussian_results)\n",
        "print(\"\\nGaussian Noise Unlearning Results:\")\n",
        "print(gaussian_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Method 2: Laplacian Noise Injection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def laplacian_noise_unlearning(model, scale=0.01):\n",
        "    \"\"\"\n",
        "    Add Laplacian noise to model parameters (better for differential privacy).\n",
        "    \n",
        "    Args:\n",
        "        model: PyTorch model\n",
        "        scale: Scale parameter of Laplacian distribution\n",
        "    \"\"\"\n",
        "    unlearned_model = deepcopy(model)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for name, param in unlearned_model.named_parameters():\n",
        "            if 'weight' in name or 'bias' in name:\n",
        "                # Add Laplacian noise\n",
        "                noise = torch.from_numpy(\n",
        "                    np.random.laplace(0, scale, param.shape)\n",
        "                ).float().to(param.device)\n",
        "                param.add_(noise)\n",
        "    \n",
        "    return unlearned_model\n",
        "\n",
        "# Test different scale values\n",
        "scale_values = [0.001, 0.005, 0.01, 0.05, 0.1]\n",
        "laplacian_results = []\n",
        "\n",
        "print(\"Testing Laplacian Noise Unlearning...\\n\")\n",
        "\n",
        "for scale in scale_values:\n",
        "    # Apply unlearning\n",
        "    unlearned_model = laplacian_noise_unlearning(model, scale=scale)\n",
        "    \n",
        "    # Evaluate\n",
        "    retain_acc = evaluate_model(unlearned_model, X_retain_tensor, y_retain_tensor)\n",
        "    forget_acc = evaluate_model(unlearned_model, X_forget_tensor, y_forget_tensor)\n",
        "    test_acc = evaluate_model(unlearned_model, X_test_tensor, y_test_tensor)\n",
        "    \n",
        "    # Calculate parameter distance\n",
        "    param_dist = calculate_parameter_distance(\n",
        "        original_model_state,\n",
        "        get_model_state_dict_copy(unlearned_model)\n",
        "    )\n",
        "    \n",
        "    laplacian_results.append({\n",
        "        'scale': scale,\n",
        "        'retain_acc': retain_acc,\n",
        "        'forget_acc': forget_acc,\n",
        "        'test_acc': test_acc,\n",
        "        'param_dist': param_dist\n",
        "    })\n",
        "    \n",
        "    print(f\"Scale={scale:.3f}: Retain={retain_acc:.2f}%, Forget={forget_acc:.2f}%, Test={test_acc:.2f}%, Dist={param_dist:.4f}\")\n",
        "\n",
        "laplacian_df = pd.DataFrame(laplacian_results)\n",
        "print(\"\\nLaplacian Noise Unlearning Results:\")\n",
        "print(laplacian_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Method 3: Adaptive Noise Scaling (Parameter Importance-Based)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def adaptive_noise_unlearning(model, X_forget, y_forget, base_sigma=0.01, importance_weight=2.0):\n",
        "    \"\"\"\n",
        "    Add noise scaled by parameter importance (gradient magnitude on forget set).\n",
        "    Parameters with larger gradients on forget set get more noise.\n",
        "    \n",
        "    Args:\n",
        "        model: PyTorch model\n",
        "        X_forget: Forget set features\n",
        "        y_forget: Forget set labels\n",
        "        base_sigma: Base noise level\n",
        "        importance_weight: How much to weight importance in noise scaling\n",
        "    \"\"\"\n",
        "    unlearned_model = deepcopy(model)\n",
        "    unlearned_model.eval()\n",
        "    \n",
        "    # Compute gradients on forget set to measure parameter importance\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    unlearned_model.zero_grad()\n",
        "    \n",
        "    outputs = unlearned_model(X_forget)\n",
        "    loss = criterion(outputs, y_forget)\n",
        "    loss.backward()\n",
        "    \n",
        "    # Store gradient magnitudes\n",
        "    grad_magnitudes = {}\n",
        "    for name, param in unlearned_model.named_parameters():\n",
        "        if param.grad is not None and ('weight' in name or 'bias' in name):\n",
        "            grad_magnitudes[name] = param.grad.abs().mean().item()\n",
        "    \n",
        "    # Normalize gradient magnitudes\n",
        "    max_grad = max(grad_magnitudes.values()) if grad_magnitudes else 1.0\n",
        "    \n",
        "    # Add adaptive noise\n",
        "    with torch.no_grad():\n",
        "        for name, param in unlearned_model.named_parameters():\n",
        "            if 'weight' in name or 'bias' in name:\n",
        "                # Scale noise by gradient magnitude (importance)\n",
        "                if name in grad_magnitudes:\n",
        "                    importance = grad_magnitudes[name] / max_grad\n",
        "                    adaptive_sigma = base_sigma * (1 + importance_weight * importance)\n",
        "                else:\n",
        "                    adaptive_sigma = base_sigma\n",
        "                \n",
        "                noise = torch.randn_like(param) * adaptive_sigma\n",
        "                param.add_(noise)\n",
        "    \n",
        "    return unlearned_model\n",
        "\n",
        "# Test different base sigma values\n",
        "base_sigma_values = [0.001, 0.005, 0.01, 0.05]\n",
        "adaptive_results = []\n",
        "\n",
        "print(\"Testing Adaptive Noise Unlearning...\\n\")\n",
        "\n",
        "for base_sigma in base_sigma_values:\n",
        "    # Apply unlearning\n",
        "    unlearned_model = adaptive_noise_unlearning(\n",
        "        model, X_forget_tensor, y_forget_tensor,\n",
        "        base_sigma=base_sigma, importance_weight=2.0\n",
        "    )\n",
        "    \n",
        "    # Evaluate\n",
        "    retain_acc = evaluate_model(unlearned_model, X_retain_tensor, y_retain_tensor)\n",
        "    forget_acc = evaluate_model(unlearned_model, X_forget_tensor, y_forget_tensor)\n",
        "    test_acc = evaluate_model(unlearned_model, X_test_tensor, y_test_tensor)\n",
        "    \n",
        "    # Calculate parameter distance\n",
        "    param_dist = calculate_parameter_distance(\n",
        "        original_model_state,\n",
        "        get_model_state_dict_copy(unlearned_model)\n",
        "    )\n",
        "    \n",
        "    adaptive_results.append({\n",
        "        'base_sigma': base_sigma,\n",
        "        'retain_acc': retain_acc,\n",
        "        'forget_acc': forget_acc,\n",
        "        'test_acc': test_acc,\n",
        "        'param_dist': param_dist\n",
        "    })\n",
        "    \n",
        "    print(f\"Base Sigma={base_sigma:.3f}: Retain={retain_acc:.2f}%, Forget={forget_acc:.2f}%, Test={test_acc:.2f}%, Dist={param_dist:.4f}\")\n",
        "\n",
        "adaptive_df = pd.DataFrame(adaptive_results)\n",
        "print(\"\\nAdaptive Noise Unlearning Results:\")\n",
        "print(adaptive_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Method 4: Layer-wise Noise Injection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def layerwise_noise_unlearning(model, layer_sigmas=None):\n",
        "    \"\"\"\n",
        "    Add different noise levels to different layers.\n",
        "    Typically, add more noise to later layers (closer to output).\n",
        "    \n",
        "    Args:\n",
        "        model: PyTorch model\n",
        "        layer_sigmas: Dict mapping layer indices to sigma values\n",
        "                     If None, uses increasing sigma for later layers\n",
        "    \"\"\"\n",
        "    unlearned_model = deepcopy(model)\n",
        "    \n",
        "    # Get all linear layers\n",
        "    linear_layers = [(name, module) for name, module in unlearned_model.named_modules() \n",
        "                     if isinstance(module, nn.Linear)]\n",
        "    \n",
        "    num_layers = len(linear_layers)\n",
        "    \n",
        "    # Default: increasing noise for later layers\n",
        "    if layer_sigmas is None:\n",
        "        layer_sigmas = {i: 0.005 * (i + 1) for i in range(num_layers)}\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for layer_idx, (name, layer) in enumerate(linear_layers):\n",
        "            sigma = layer_sigmas.get(layer_idx, 0.01)\n",
        "            \n",
        "            # Add noise to weights\n",
        "            if layer.weight is not None:\n",
        "                noise = torch.randn_like(layer.weight) * sigma\n",
        "                layer.weight.add_(noise)\n",
        "            \n",
        "            # Add noise to bias\n",
        "            if layer.bias is not None:\n",
        "                noise = torch.randn_like(layer.bias) * sigma\n",
        "                layer.bias.add_(noise)\n",
        "    \n",
        "    return unlearned_model\n",
        "\n",
        "# Test different layer-wise strategies\n",
        "strategies = [\n",
        "    {'name': 'Uniform', 'sigmas': {0: 0.01, 1: 0.01, 2: 0.01, 3: 0.01}},\n",
        "    {'name': 'Increasing', 'sigmas': {0: 0.005, 1: 0.01, 2: 0.015, 3: 0.02}},\n",
        "    {'name': 'Decreasing', 'sigmas': {0: 0.02, 1: 0.015, 2: 0.01, 3: 0.005}},\n",
        "    {'name': 'Output-heavy', 'sigmas': {0: 0.005, 1: 0.005, 2: 0.01, 3: 0.03}},\n",
        "]\n",
        "\n",
        "layerwise_results = []\n",
        "\n",
        "print(\"Testing Layer-wise Noise Unlearning...\\n\")\n",
        "\n",
        "for strategy in strategies:\n",
        "    # Apply unlearning\n",
        "    unlearned_model = layerwise_noise_unlearning(model, layer_sigmas=strategy['sigmas'])\n",
        "    \n",
        "    # Evaluate\n",
        "    retain_acc = evaluate_model(unlearned_model, X_retain_tensor, y_retain_tensor)\n",
        "    forget_acc = evaluate_model(unlearned_model, X_forget_tensor, y_forget_tensor)\n",
        "    test_acc = evaluate_model(unlearned_model, X_test_tensor, y_test_tensor)\n",
        "    \n",
        "    # Calculate parameter distance\n",
        "    param_dist = calculate_parameter_distance(\n",
        "        original_model_state,\n",
        "        get_model_state_dict_copy(unlearned_model)\n",
        "    )\n",
        "    \n",
        "    layerwise_results.append({\n",
        "        'strategy': strategy['name'],\n",
        "        'retain_acc': retain_acc,\n",
        "        'forget_acc': forget_acc,\n",
        "        'test_acc': test_acc,\n",
        "        'param_dist': param_dist\n",
        "    })\n",
        "    \n",
        "    print(f\"{strategy['name']:15s}: Retain={retain_acc:.2f}%, Forget={forget_acc:.2f}%, Test={test_acc:.2f}%, Dist={param_dist:.4f}\")\n",
        "\n",
        "layerwise_df = pd.DataFrame(layerwise_results)\n",
        "print(\"\\nLayer-wise Noise Unlearning Results:\")\n",
        "print(layerwise_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Method 5: Gradient-based Noise (Noise Proportional to Gradient)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def gradient_based_noise_unlearning(model, X_forget, y_forget, noise_multiplier=0.1):\n",
        "    \"\"\"\n",
        "    Add noise proportional to gradient magnitude on forget set.\n",
        "    This targets parameters most responsible for remembering the forget set.\n",
        "    \n",
        "    Args:\n",
        "        model: PyTorch model\n",
        "        X_forget: Forget set features\n",
        "        y_forget: Forget set labels\n",
        "        noise_multiplier: Multiplier for gradient-based noise\n",
        "    \"\"\"\n",
        "    unlearned_model = deepcopy(model)\n",
        "    unlearned_model.eval()\n",
        "    \n",
        "    # Compute gradients on forget set\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    unlearned_model.zero_grad()\n",
        "    \n",
        "    outputs = unlearned_model(X_forget)\n",
        "    loss = criterion(outputs, y_forget)\n",
        "    loss.backward()\n",
        "    \n",
        "    # Add noise proportional to gradient\n",
        "    with torch.no_grad():\n",
        "        for name, param in unlearned_model.named_parameters():\n",
        "            if param.grad is not None and ('weight' in name or 'bias' in name):\n",
        "                # Noise magnitude proportional to gradient magnitude\n",
        "                grad_magnitude = param.grad.abs()\n",
        "                noise = torch.randn_like(param) * grad_magnitude * noise_multiplier\n",
        "                param.add_(noise)\n",
        "    \n",
        "    return unlearned_model\n",
        "\n",
        "# Test different noise multipliers\n",
        "noise_multipliers = [0.05, 0.1, 0.2, 0.5, 1.0]\n",
        "gradient_results = []\n",
        "\n",
        "print(\"Testing Gradient-based Noise Unlearning...\\n\")\n",
        "\n",
        "for multiplier in noise_multipliers:\n",
        "    # Apply unlearning\n",
        "    unlearned_model = gradient_based_noise_unlearning(\n",
        "        model, X_forget_tensor, y_forget_tensor,\n",
        "        noise_multiplier=multiplier\n",
        "    )\n",
        "    \n",
        "    # Evaluate\n",
        "    retain_acc = evaluate_model(unlearned_model, X_retain_tensor, y_retain_tensor)\n",
        "    forget_acc = evaluate_model(unlearned_model, X_forget_tensor, y_forget_tensor)\n",
        "    test_acc = evaluate_model(unlearned_model, X_test_tensor, y_test_tensor)\n",
        "    \n",
        "    # Calculate parameter distance\n",
        "    param_dist = calculate_parameter_distance(\n",
        "        original_model_state,\n",
        "        get_model_state_dict_copy(unlearned_model)\n",
        "    )\n",
        "    \n",
        "    gradient_results.append({\n",
        "        'multiplier': multiplier,\n",
        "        'retain_acc': retain_acc,\n",
        "        'forget_acc': forget_acc,\n",
        "        'test_acc': test_acc,\n",
        "        'param_dist': param_dist\n",
        "    })\n",
        "    \n",
        "    print(f\"Multiplier={multiplier:.2f}: Retain={retain_acc:.2f}%, Forget={forget_acc:.2f}%, Test={test_acc:.2f}%, Dist={param_dist:.4f}\")\n",
        "\n",
        "gradient_df = pd.DataFrame(gradient_results)\n",
        "print(\"\\nGradient-based Noise Unlearning Results:\")\n",
        "print(gradient_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Comparison and Visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comparison plots\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
        "fig.suptitle('Comparison of Noise-Based Machine Unlearning Methods', fontsize=16, y=1.00)\n",
        "\n",
        "# 1. Gaussian Noise\n",
        "ax = axes[0, 0]\n",
        "ax.plot(gaussian_df['sigma'], gaussian_df['retain_acc'], 'o-', label='Retain', linewidth=2)\n",
        "ax.plot(gaussian_df['sigma'], gaussian_df['forget_acc'], 's-', label='Forget', linewidth=2)\n",
        "ax.plot(gaussian_df['sigma'], gaussian_df['test_acc'], '^-', label='Test', linewidth=2)\n",
        "ax.set_xlabel('Sigma')\n",
        "ax.set_ylabel('Accuracy (%)')\n",
        "ax.set_title('Gaussian Noise')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# 2. Laplacian Noise\n",
        "ax = axes[0, 1]\n",
        "ax.plot(laplacian_df['scale'], laplacian_df['retain_acc'], 'o-', label='Retain', linewidth=2)\n",
        "ax.plot(laplacian_df['scale'], laplacian_df['forget_acc'], 's-', label='Forget', linewidth=2)\n",
        "ax.plot(laplacian_df['scale'], laplacian_df['test_acc'], '^-', label='Test', linewidth=2)\n",
        "ax.set_xlabel('Scale')\n",
        "ax.set_ylabel('Accuracy (%)')\n",
        "ax.set_title('Laplacian Noise')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# 3. Adaptive Noise\n",
        "ax = axes[0, 2]\n",
        "ax.plot(adaptive_df['base_sigma'], adaptive_df['retain_acc'], 'o-', label='Retain', linewidth=2)\n",
        "ax.plot(adaptive_df['base_sigma'], adaptive_df['forget_acc'], 's-', label='Forget', linewidth=2)\n",
        "ax.plot(adaptive_df['base_sigma'], adaptive_df['test_acc'], '^-', label='Test', linewidth=2)\n",
        "ax.set_xlabel('Base Sigma')\n",
        "ax.set_ylabel('Accuracy (%)')\n",
        "ax.set_title('Adaptive Noise')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# 4. Layer-wise Noise\n",
        "ax = axes[1, 0]\n",
        "x_pos = np.arange(len(layerwise_df))\n",
        "width = 0.25\n",
        "ax.bar(x_pos - width, layerwise_df['retain_acc'], width, label='Retain')\n",
        "ax.bar(x_pos, layerwise_df['forget_acc'], width, label='Forget')\n",
        "ax.bar(x_pos + width, layerwise_df['test_acc'], width, label='Test')\n",
        "ax.set_xlabel('Strategy')\n",
        "ax.set_ylabel('Accuracy (%)')\n",
        "ax.set_title('Layer-wise Noise')\n",
        "ax.set_xticks(x_pos)\n",
        "ax.set_xticklabels(layerwise_df['strategy'], rotation=45, ha='right')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# 5. Gradient-based Noise\n",
        "ax = axes[1, 1]\n",
        "ax.plot(gradient_df['multiplier'], gradient_df['retain_acc'], 'o-', label='Retain', linewidth=2)\n",
        "ax.plot(gradient_df['multiplier'], gradient_df['forget_acc'], 's-', label='Forget', linewidth=2)\n",
        "ax.plot(gradient_df['multiplier'], gradient_df['test_acc'], '^-', label='Test', linewidth=2)\n",
        "ax.set_xlabel('Noise Multiplier')\n",
        "ax.set_ylabel('Accuracy (%)')\n",
        "ax.set_title('Gradient-based Noise')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# 6. Parameter Distance Comparison\n",
        "ax = axes[1, 2]\n",
        "methods = ['Gaussian\\n(σ=0.01)', 'Laplacian\\n(s=0.01)', 'Adaptive\\n(σ=0.01)', \n",
        "           'Layer-wise\\n(Increasing)', 'Gradient\\n(m=0.1)']\n",
        "distances = [\n",
        "    gaussian_df[gaussian_df['sigma'] == 0.01]['param_dist'].values[0],\n",
        "    laplacian_df[laplacian_df['scale'] == 0.01]['param_dist'].values[0],\n",
        "    adaptive_df[adaptive_df['base_sigma'] == 0.01]['param_dist'].values[0],\n",
        "    layerwise_df[layerwise_df['strategy'] == 'Increasing']['param_dist'].values[0],\n",
        "    gradient_df[gradient_df['multiplier'] == 0.1]['param_dist'].values[0]\n",
        "]\n",
        "ax.bar(methods, distances, color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd'])\n",
        "ax.set_ylabel('Parameter Distance')\n",
        "ax.set_title('Parameter Distance from Original')\n",
        "ax.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Summary Table and Metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create summary table with best configuration from each method\n",
        "summary_data = [\n",
        "    {\n",
        "        'Method': 'Original Model',\n",
        "        'Retain Acc': evaluate_model(model, X_retain_tensor, y_retain_tensor),\n",
        "        'Forget Acc': evaluate_model(model, X_forget_tensor, y_forget_tensor),\n",
        "        'Test Acc': evaluate_model(model, X_test_tensor, y_test_tensor),\n",
        "        'Param Dist': 0.0,\n",
        "        'Config': 'N/A'\n",
        "    },\n",
        "    {\n",
        "        'Method': 'Gaussian Noise',\n",
        "        'Retain Acc': gaussian_df.iloc[2]['retain_acc'],\n",
        "        'Forget Acc': gaussian_df.iloc[2]['forget_acc'],\n",
        "        'Test Acc': gaussian_df.iloc[2]['test_acc'],\n",
        "        'Param Dist': gaussian_df.iloc[2]['param_dist'],\n",
        "        'Config': f\"σ={gaussian_df.iloc[2]['sigma']}\"\n",
        "    },\n",
        "    {\n",
        "        'Method': 'Laplacian Noise',\n",
        "        'Retain Acc': laplacian_df.iloc[2]['retain_acc'],\n",
        "        'Forget Acc': laplacian_df.iloc[2]['forget_acc'],\n",
        "        'Test Acc': laplacian_df.iloc[2]['test_acc'],\n",
        "        'Param Dist': laplacian_df.iloc[2]['param_dist'],\n",
        "        'Config': f\"scale={laplacian_df.iloc[2]['scale']}\"\n",
        "    },\n",
        "    {\n",
        "        'Method': 'Adaptive Noise',\n",
        "        'Retain Acc': adaptive_df.iloc[2]['retain_acc'],\n",
        "        'Forget Acc': adaptive_df.iloc[2]['forget_acc'],\n",
        "        'Test Acc': adaptive_df.iloc[2]['test_acc'],\n",
        "        'Param Dist': adaptive_df.iloc[2]['param_dist'],\n",
        "        'Config': f\"base_σ={adaptive_df.iloc[2]['base_sigma']}\"\n",
        "    },\n",
        "    {\n",
        "        'Method': 'Layer-wise Noise',\n",
        "        'Retain Acc': layerwise_df.iloc[1]['retain_acc'],\n",
        "        'Forget Acc': layerwise_df.iloc[1]['forget_acc'],\n",
        "        'Test Acc': layerwise_df.iloc[1]['test_acc'],\n",
        "        'Param Dist': layerwise_df.iloc[1]['param_dist'],\n",
        "        'Config': layerwise_df.iloc[1]['strategy']\n",
        "    },\n",
        "    {\n",
        "        'Method': 'Gradient-based Noise',\n",
        "        'Retain Acc': gradient_df.iloc[1]['retain_acc'],\n",
        "        'Forget Acc': gradient_df.iloc[1]['forget_acc'],\n",
        "        'Test Acc': gradient_df.iloc[1]['test_acc'],\n",
        "        'Param Dist': gradient_df.iloc[1]['param_dist'],\n",
        "        'Config': f\"mult={gradient_df.iloc[1]['multiplier']}\"\n",
        "    }\n",
        "]\n",
        "\n",
        "summary_df = pd.DataFrame(summary_data)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SUMMARY: Noise-Based Machine Unlearning Methods\")\n",
        "print(\"=\"*80)\n",
        "print(summary_df.to_string(index=False))\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Calculate unlearning metrics\n",
        "print(\"\\nUnlearning Effectiveness Metrics:\")\n",
        "print(\"-\" * 80)\n",
        "original_forget_acc = summary_df.iloc[0]['Forget Acc']\n",
        "\n",
        "for idx, row in summary_df.iterrows():\n",
        "    if idx == 0:\n",
        "        continue\n",
        "    \n",
        "    forget_drop = original_forget_acc - row['Forget Acc']\n",
        "    retain_drop = summary_df.iloc[0]['Retain Acc'] - row['Retain Acc']\n",
        "    test_drop = summary_df.iloc[0]['Test Acc'] - row['Test Acc']\n",
        "    \n",
        "    # Unlearning quality score: high forget drop, low retain drop\n",
        "    quality_score = forget_drop - retain_drop\n",
        "    \n",
        "    print(f\"{row['Method']:25s} | Forget Drop: {forget_drop:6.2f}% | Retain Drop: {retain_drop:6.2f}% | Quality: {quality_score:6.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Retrain from Scratch (Gold Standard Baseline)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train a new model from scratch on only the retain set\n",
        "# This is the gold standard for machine unlearning\n",
        "retrain_model = TabularClassifier(\n",
        "    input_size=n_features,\n",
        "    hidden_sizes=[64, 32, 16],\n",
        "    num_classes=2,\n",
        "    dropout=0.3\n",
        ").to(device)\n",
        "\n",
        "print(\"Training model from scratch on retain set only...\")\n",
        "retrain_losses = train_model(retrain_model, X_retain_tensor, y_retain_tensor, \n",
        "                             epochs=100, lr=0.001, verbose=False)\n",
        "\n",
        "# Evaluate retrained model\n",
        "retrain_retain_acc = evaluate_model(retrain_model, X_retain_tensor, y_retain_tensor)\n",
        "retrain_forget_acc = evaluate_model(retrain_model, X_forget_tensor, y_forget_tensor)\n",
        "retrain_test_acc = evaluate_model(retrain_model, X_test_tensor, y_test_tensor)\n",
        "\n",
        "print(\"\\n=== Retrained Model (Gold Standard) ===\")\n",
        "print(f\"Retain Set Accuracy: {retrain_retain_acc:.2f}%\")\n",
        "print(f\"Forget Set Accuracy: {retrain_forget_acc:.2f}%\")\n",
        "print(f\"Test Set Accuracy: {retrain_test_acc:.2f}%\")\n",
        "\n",
        "# Add to summary\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Comparison with Gold Standard (Retrain from Scratch):\")\n",
        "print(\"=\"*80)\n",
        "print(f\"{'Method':<25s} | {'Retain Acc':>10s} | {'Forget Acc':>10s} | {'Test Acc':>10s}\")\n",
        "print(\"-\" * 80)\n",
        "print(f\"{'Retrain (Gold Standard)':<25s} | {retrain_retain_acc:>9.2f}% | {retrain_forget_acc:>9.2f}% | {retrain_test_acc:>9.2f}%\")\n",
        "for idx, row in summary_df.iterrows():\n",
        "    if idx == 0:\n",
        "        continue\n",
        "    print(f\"{row['Method']:<25s} | {row['Retain Acc']:>9.2f}% | {row['Forget Acc']:>9.2f}% | {row['Test Acc']:>9.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Unlearning Effectiveness Visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a comprehensive visualization of unlearning effectiveness\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "fig.suptitle('Unlearning Effectiveness Analysis', fontsize=16)\n",
        "\n",
        "# 1. Forget vs Retain Accuracy Trade-off\n",
        "ax = axes[0, 0]\n",
        "for idx, row in summary_df.iterrows():\n",
        "    if idx == 0:\n",
        "        ax.scatter(row['Retain Acc'], row['Forget Acc'], s=200, marker='*', \n",
        "                  c='red', label='Original', zorder=5, edgecolors='black', linewidth=2)\n",
        "    else:\n",
        "        ax.scatter(row['Retain Acc'], row['Forget Acc'], s=100, \n",
        "                  label=row['Method'], alpha=0.7, edgecolors='black', linewidth=1)\n",
        "\n",
        "ax.scatter(retrain_retain_acc, retrain_forget_acc, s=200, marker='D', \n",
        "          c='green', label='Retrain (Gold)', zorder=5, edgecolors='black', linewidth=2)\n",
        "ax.set_xlabel('Retain Set Accuracy (%)', fontsize=11)\n",
        "ax.set_ylabel('Forget Set Accuracy (%)', fontsize=11)\n",
        "ax.set_title('Forget vs Retain Accuracy Trade-off\\n(Lower-Right is Better)', fontsize=12)\n",
        "ax.legend(fontsize=8, loc='best')\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# 2. Unlearning Quality Score\n",
        "ax = axes[0, 1]\n",
        "methods_list = []\n",
        "quality_scores = []\n",
        "colors_list = []\n",
        "\n",
        "for idx, row in summary_df.iterrows():\n",
        "    if idx == 0:\n",
        "        continue\n",
        "    forget_drop = summary_df.iloc[0]['Forget Acc'] - row['Forget Acc']\n",
        "    retain_drop = summary_df.iloc[0]['Retain Acc'] - row['Retain Acc']\n",
        "    quality = forget_drop - retain_drop\n",
        "    methods_list.append(row['Method'])\n",
        "    quality_scores.append(quality)\n",
        "    colors_list.append('#2ca02c' if quality > 0 else '#d62728')\n",
        "\n",
        "bars = ax.barh(methods_list, quality_scores, color=colors_list, alpha=0.7, edgecolor='black')\n",
        "ax.axvline(x=0, color='black', linestyle='--', linewidth=1)\n",
        "ax.set_xlabel('Quality Score (Forget Drop - Retain Drop)', fontsize=11)\n",
        "ax.set_title('Unlearning Quality Score\\n(Higher is Better)', fontsize=12)\n",
        "ax.grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "# 3. Accuracy Changes from Original\n",
        "ax = axes[1, 0]\n",
        "x_pos = np.arange(len(methods_list))\n",
        "width = 0.35\n",
        "\n",
        "forget_drops = [summary_df.iloc[0]['Forget Acc'] - summary_df.iloc[i+1]['Forget Acc'] for i in range(len(methods_list))]\n",
        "retain_drops = [summary_df.iloc[0]['Retain Acc'] - summary_df.iloc[i+1]['Retain Acc'] for i in range(len(methods_list))]\n",
        "\n",
        "ax.bar(x_pos - width/2, forget_drops, width, label='Forget Acc Drop', color='#ff7f0e', alpha=0.7, edgecolor='black')\n",
        "ax.bar(x_pos + width/2, retain_drops, width, label='Retain Acc Drop', color='#1f77b4', alpha=0.7, edgecolor='black')\n",
        "\n",
        "ax.set_ylabel('Accuracy Drop (%)', fontsize=11)\n",
        "ax.set_title('Accuracy Changes from Original Model\\n(Higher Forget Drop is Better)', fontsize=12)\n",
        "ax.set_xticks(x_pos)\n",
        "ax.set_xticklabels(methods_list, rotation=45, ha='right', fontsize=9)\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3, axis='y')\n",
        "ax.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
        "\n",
        "# 4. Parameter Distance vs Unlearning Effectiveness\n",
        "ax = axes[1, 1]\n",
        "param_dists = [summary_df.iloc[i+1]['Param Dist'] for i in range(len(methods_list))]\n",
        "forget_accs = [summary_df.iloc[i+1]['Forget Acc'] for i in range(len(methods_list))]\n",
        "\n",
        "scatter = ax.scatter(param_dists, forget_accs, s=100, c=quality_scores, \n",
        "                    cmap='RdYlGn', alpha=0.7, edgecolors='black', linewidth=1)\n",
        "\n",
        "# Add method labels\n",
        "for i, method in enumerate(methods_list):\n",
        "    ax.annotate(method.split()[0], (param_dists[i], forget_accs[i]), \n",
        "               fontsize=8, ha='center', va='bottom')\n",
        "\n",
        "ax.set_xlabel('Parameter Distance from Original', fontsize=11)\n",
        "ax.set_ylabel('Forget Set Accuracy (%)', fontsize=11)\n",
        "ax.set_title('Parameter Distance vs Forget Accuracy\\n(Lower Forget Acc is Better)', fontsize=12)\n",
        "ax.grid(True, alpha=0.3)\n",
        "plt.colorbar(scatter, ax=ax, label='Quality Score')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Key Findings and Recommendations\n",
        "\n",
        "### Understanding the Results:\n",
        "\n",
        "1. **Forget Set Accuracy**: Should decrease after unlearning (model \"forgets\" this data)\n",
        "2. **Retain Set Accuracy**: Should remain high (model maintains knowledge of retained data)\n",
        "3. **Test Set Accuracy**: Overall model performance indicator\n",
        "4. **Parameter Distance**: How much the model changed from original\n",
        "\n",
        "### Method Characteristics:\n",
        "\n",
        "- **Gaussian Noise**: Simple, uniform perturbation across all parameters. Easy to implement and tune.\n",
        "- **Laplacian Noise**: Better for differential privacy guarantees due to heavier tails. Provides formal privacy bounds.\n",
        "- **Adaptive Noise**: Targets important parameters (high gradients on forget set) more aggressively. Better trade-off between forgetting and retaining.\n",
        "- **Layer-wise Noise**: Allows fine-grained control per layer. Can focus noise on output layers that directly influence predictions.\n",
        "- **Gradient-based Noise**: Focuses on parameters most responsible for forget set. Noise magnitude scales with parameter importance.\n",
        "\n",
        "### Trade-offs:\n",
        "\n",
        "- **More noise** → Better forgetting but worse retain/test performance\n",
        "- **Less noise** → Better retain/test performance but less effective forgetting\n",
        "- **Adaptive methods** → Better balance between forgetting and retaining\n",
        "- **Computational cost**: Gradient-based and adaptive methods require forward/backward pass on forget set\n",
        "\n",
        "### Best Practices:\n",
        "\n",
        "1. **Start small**: Begin with small noise levels and increase gradually\n",
        "2. **Monitor both sets**: Track both forget and retain set performance\n",
        "3. **Use adaptive methods**: For better trade-offs, consider gradient-based or adaptive noise\n",
        "4. **Compare to baseline**: Always compare against retrain-from-scratch baseline\n",
        "5. **Consider privacy**: Use Laplacian noise if differential privacy guarantees are needed\n",
        "6. **Layer targeting**: Focus noise on later layers (closer to output) for more targeted forgetting\n",
        "\n",
        "### When to Use Each Method:\n",
        "\n",
        "- **Gaussian Noise**: Quick experiments, baseline comparisons\n",
        "- **Laplacian Noise**: When differential privacy is required\n",
        "- **Adaptive Noise**: When you want to minimize impact on retained data\n",
        "- **Layer-wise Noise**: When you know which layers are most important\n",
        "- **Gradient-based Noise**: When you want targeted, efficient unlearning\n",
        "\n",
        "### Limitations:\n",
        "\n",
        "1. Noise-based methods are **approximate** - they don't guarantee complete removal of information\n",
        "2. May require careful tuning of noise levels\n",
        "3. Can degrade overall model performance\n",
        "4. No formal guarantees about what information is removed\n",
        "5. May not work well for very small forget sets or highly correlated data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
