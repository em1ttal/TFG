{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions and Loss:\n",
      "  Predicted: 16.40\n",
      "  Actual: 15.00\n",
      "  Loss: 1.96\n",
      "\n",
      "Gradients (∇_θ L):\n",
      "  ∂L/∂w1 = 5.6000\n",
      "  ∂L/∂w2 = 11.2000\n",
      "  ∂L/∂w3 = 22.4000\n",
      "\n",
      "Gradient Norms (||∇_θ L||):\n",
      "  ||∇_w1 L|| = 5.6000\n",
      "  ||∇_w2 L|| = 11.2000\n",
      "  ||∇_w3 L|| = 22.4000\n",
      "\n",
      "Maximum gradient norm: 22.4000\n",
      "\n",
      "Scaling factors α(θ) = ||∇_θ L|| / max(||∇_θ L||):\n",
      "  α(w1) = 5.6000 / 22.4000 = 0.2500\n",
      "  α(w2) = 11.2000 / 22.4000 = 0.5000\n",
      "  α(w3) = 22.4000 / 22.4000 = 1.0000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Simple model: just 3 parameters for clarity\n",
    "class TinyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.w1 = nn.Parameter(torch.tensor([2.0]))\n",
    "        self.w2 = nn.Parameter(torch.tensor([1.5]))\n",
    "        self.w3 = nn.Parameter(torch.tensor([0.8]))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.w1 * x + self.w2 * x**2 + self.w3 * x**3\n",
    "\n",
    "model = TinyModel()\n",
    "\n",
    "# Forget data\n",
    "x_forget = torch.tensor([2.0])\n",
    "y_forget = torch.tensor([15.0])\n",
    "\n",
    "# Compute loss and gradients\n",
    "model.zero_grad()\n",
    "y_pred = model(x_forget)\n",
    "loss = (y_forget - y_pred) ** 2\n",
    "loss.backward()\n",
    "\n",
    "print(\"Predictions and Loss:\")\n",
    "print(f\"  Predicted: {y_pred.item():.2f}\")\n",
    "print(f\"  Actual: {y_forget.item():.2f}\")\n",
    "print(f\"  Loss: {loss.item():.2f}\")\n",
    "print()\n",
    "\n",
    "# Extract gradients\n",
    "print(\"Gradients (∇_θ L):\")\n",
    "print(f\"  ∂L/∂w1 = {model.w1.grad.item():.4f}\")\n",
    "print(f\"  ∂L/∂w2 = {model.w2.grad.item():.4f}\")\n",
    "print(f\"  ∂L/∂w3 = {model.w3.grad.item():.4f}\")\n",
    "print()\n",
    "\n",
    "# Compute gradient norms (for single parameters, norm = absolute value)\n",
    "grad_norms = {\n",
    "    'w1': abs(model.w1.grad.item()),\n",
    "    'w2': abs(model.w2.grad.item()),\n",
    "    'w3': abs(model.w3.grad.item())\n",
    "}\n",
    "\n",
    "print(\"Gradient Norms (||∇_θ L||):\")\n",
    "for name, norm in grad_norms.items():\n",
    "    print(f\"  ||∇_{name} L|| = {norm:.4f}\")\n",
    "print()\n",
    "\n",
    "# Find maximum gradient norm\n",
    "max_grad_norm = max(grad_norms.values())\n",
    "print(f\"Maximum gradient norm: {max_grad_norm:.4f}\")\n",
    "print()\n",
    "\n",
    "# Compute α(θ) for each parameter\n",
    "print(\"Scaling factors α(θ) = ||∇_θ L|| / max(||∇_θ L||):\")\n",
    "alphas = {}\n",
    "for name, norm in grad_norms.items():\n",
    "    alpha = norm / max_grad_norm\n",
    "    alphas[name] = alpha\n",
    "    print(f\"  α({name}) = {norm:.4f} / {max_grad_norm:.4f} = {alpha:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 2579480,
     "sourceId": 4532039,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30559,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
